# VIALM
This repository offers a survey and benchmark for Visual Impairment Assistance using Language Models (VIALM).
## 1. Task Illustration
AThe following image is a sample input and output of VIALM.
Its input is a pair of a visual image of the environment (the left image) and a user request in human language (the grey box).
The yellow box shows the output guidance for VI users to complete the request within the environment (the right image).
The output should grounded and fine-grained for VI users to follow easily.
![VIALM](./images/VIALM_task.png 'VIALM_task')
## 2. Paper Collections
For the survey part, the following are related papers. It will be continually updated.
### 2.1 Large Language models (LLMs)

### 2.2 Visual-Language Models (VLMs)

### 2.3 Embodied Agents

## 3. Benchmark Evaluation
### 3.1 Benchmark Annotations
### 3.2 LM Predictions



